{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antfolk/BMEN35_2025/blob/main/Session8/BMEN35_shap_values_assignment8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 8\n",
        "## Fill in your name below\n",
        "--- FILL IN YOUR NAME HERE ---\n",
        "\n",
        "## Your mission is now the following:\n",
        "\n",
        "You will explore explainability using SHapley Additive exPlanations (SHAP) as discussed in the lecture. A book on explainabilty can be found on https://christophm.github.io/interpretable-ml-book/  \n",
        "\n",
        "Some specifics for this assignment:\n",
        "*   Use the breast_cancer dataset (available in sklearn)\n",
        "*   Try two different classifiers (Decision Trees and ExtraTreesClassifier from sklearn)\n",
        "*   Split the data using sklearns train_test_split with test_size = 0.3 and random_state = 43\n",
        "*   **Make three different plots for each classifier** (a \"global\" feature importance plot, one \"local\" feature plot for one instance of class 0, one \"local\" feature plot for one instance of class 1).\n",
        "*   **Print accuracy and classification report for each classifier**\n",
        "\n",
        "You will use SHAP for Python (documentation found here, admittedly not great, but sometimes life gives you lemons)\n",
        "https://shap.readthedocs.io/en/stable/index.html . You might also want to have a look at the github repo at https://github.com/shap/shap/tree/master . You can check the code and examples there to get some ideas on implementation.\n",
        "\n",
        "Some hints that might come in handy:\n",
        "*   Pandas might be nice to import data (will give you names of features).\n",
        "*   TreeExplainer could be a thing.\n",
        "*   Bars and waterfalls are cool.\n",
        "*   Check dimensions of output from explainer object when called on the (test) dataset. For classification (in these cases) a 3D array (a,b,c) where c is the number of classes is the output.\n",
        "*   If you use any interactive SHAP plots (e.g., force_plot or decision_plot), remember to run: shap.initjs()\n",
        "\n",
        "\n",
        "**Hand in the notebook as usual and comment on if there any differences in how features are used in the different classifiers.**\n"
      ],
      "metadata": {
        "id": "cb0tUF8G1rV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# I will start you off with this\n",
        "!pip install shap\n",
        "# You will figure out the rest...."
      ],
      "metadata": {
        "id": "oGLWZkZG5f0q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}